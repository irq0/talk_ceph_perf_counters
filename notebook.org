#+TITLE: Understanding Ceph One Performance Counter at a Time
#+AUTHOR: Marcel Lauhoff
#+OPTIONS: H:4 toc:2 num:nil
#+PROPERTY: header-args :noweb no-export
#+PROPERTY: header-args :var source="/compile2/ceph/wip"
#+PROPERTY: header-args+ :var build="/compile2/ceph/wip/build"
#+PROPERTY: header-args+ :var out="/compile2/ceph/wip/build/out"
#+PROPERTY: header-args+ :var asok="/compile2/ceph/wip/build/asok"
#+PROPERTY: header-args+ :var run_id="297838a4-5a65-4c97-a708-43f35c4b1f46"

* Introduction
This is the companion org-mode notebook for the [[https://sched.co/1ktW7][Understanding Ceph One Performance Counter at a Time]]
session at [[https://events.linuxfoundation.org/cephalocon/][Cephalocon]] 2024.

Code and data in here are the source for the presentation slides.

The notebook and presentation is organized into a sequence to experiments.
Each running a workload and then measuring it's effects.

* Setup
/Housekeeping and utility code to run queries and experiments later on/

Start a basic "vstart" cluster
#+begin_src bash
MON=3 OSD=3 MGR=1 RGW=1 MDS=2 NFS=0 ../src/vstart.sh -n
#+end_src

#+RESULTS:

#+caption: Convenience snippet. Used by most scripts later on. Re-evaluate when restarting the cluster.
#+name: env
#+begin_src bash
source  $build/vstart_environment.sh
#+end_src

#+RESULTS: env

** Cluster Configuration
#+caption: Create a S3 test bucket
#+begin_src bash :noweb yes :results output verbatim
<<env_s3>>
s3 mb s3://testbucket
#+end_src

#+RESULTS:
: Bucket 's3://testbucket/' created

#+caption: Create pool for =fio=
#+begin_src bash :noweb yes :results output verbatim
<<env>>
ceph osd pool create rbd 2>&1
ceph osd pool application enable rbd benchmarks
#+end_src

#+RESULTS:
: 2025-01-27T21:36:30.821+0100 7ff9266296c0 -1 WARNING: all dangerous and experimental features are enabled.
: 2025-01-27T21:36:30.845+0100 7ff9266296c0 -1 WARNING: all dangerous and experimental features are enabled.
: pool 'rbd' created

#+caption: Disable RGW background threads
#+begin_src bash :noweb yes
<<env>>
ceph config set global rgw_enable_quota_threads false 2>/dev/null
ceph config set global rgw_enable_gc_threads false 2>/dev/null
ceph config set global rgw_enable_lc_threads false 2>/dev/null
ceph health mute MGR_MODULE_ERROR 2>/dev/null
#+end_src

#+RESULTS:

** Accessing Admin Sockets, Ceph Version, Cluster Status
Use either =ceph tell <target>= or =ceph daemon <asok>=

#+begin_src bash :noweb yes :results output verbatim
<<env>>
ceph tell osd.0 version 2>/dev/null
ceph daemon $asok/osd.0.asok version 2>/dev/null
( cd $build && git describe)
ceph -s 2>/dev/null
#+end_src

#+RESULTS:
#+begin_example
{
    "version": "Development",
    "release": "squid",
    "release_type": "dev"
}
{
    "version": "Development",
    "release": "squid",
    "release_type": "dev"
}
v19.3.0-6974-gd170809490b
  cluster:
    id:     7e284701-b88f-4831-976d-60c8e35cd0c3
    health: HEALTH_OK
            (muted: MGR_MODULE_ERROR)

  services:
    mon: 3 daemons, quorum a,b,c (age 5h)
    mgr: x(active, since 5h)
    mds: 1/1 daemons up, 1 standby
    osd: 3 osds: 3 up (since 5h), 3 in (since 5h)
    rgw: 1 daemon active (1 hosts, 1 zones)

  data:
    volumes: 1/1 healthy
    pools:   10 pools, 370 pgs
    objects: 275 objects, 13 KiB
    usage:   3.0 GiB used, 300 GiB / 303 GiB avail
    pgs:     0.270% pgs unknown
             369 active+clean
             1   unknown

  io:
    client:   102 B/s wr, 0 op/s rd, 0 op/s wr

#+end_example

In this notebook we use =ceph tell= for all daemons and =ceph daemon= for clients such as =fio= or =radosgw=

** Utilities

#+caption: Functions to get lists of Ceph daemons
#+name: get_daemons
#+begin_src bash
mons () {
    ceph -f json mon dump 2>/dev/null | jq -r '"mon.\(.mons[].name)"'
}
osds () {
    ceph -f json osd dump 2>/dev/null | jq -r '"osd.\(.osds[].osd)"'
}
mgrs () {
    ceph -f json mgr dump 2>/dev/null | jq -r '"mgr.\(.active_name)"'
}

ceph_daemons () {
    mons
    osds
    mgrs
}
#+end_src

#+RESULTS: get_daemons

#+caption: Functions to reset performance counters
#+name: reset_fns
#+begin_src bash :noweb yes
<<get_daemons>>
reset_rgw_perf_counters () {
    ceph daemon $out/radosgw.8000.asok perf reset all
}
reset_daemon_perf_counters ()  {
    ceph_daemons | xargs -I{} ceph tell '{}' perf reset all &>/dev/null
}
#+end_src

#+RESULTS: reset_fns

#+caption: Functions to create files with test data
#+name: testfile
#+begin_src bash
testfile_4mb () {
    local filename="/tmp/random_4mb"
    if ! [[ -r $filename ]]; then
	dd if=/dev/urandom of="$filename" bs=4M count=1
    fi
    echo "$filename"
}
#+end_src

#+RESULTS: testfile

#+caption: Generate a environment that has credentials for RGW in the environment
#+begin_src bash :noweb yes :results code replace :tangle rgw_env
<<env>>
creds=($(radosgw-admin user info --uid testid 2>/dev/null | jq -r '.keys[0] | [.access_key, .secret_key] | @tsv'))
access_key="${creds[@]:0:1}"
secret_key="${creds[@]:1:1}"

cat <<EOF
access_key="$access_key"
secret_key="$secret_key"

function s3 () {
   s3cmd --access_key "$access_key" \
	  --secret_key "$secret_key" \
	  --signature-v2 \
	  --host=http://localhost:8000 \
	  --no-ssl \
	  --host-bucket="http://localhost:8000/%(bucket)" \
	  \$@
}
EOF
#+end_src

#+name: env_s3
#+RESULTS:
#+begin_src bash
access_key="0555b35654ad1656d804"
secret_key="h7GhxuBLTrlhVUyxSPUKUV8r/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="

function s3 () {
   s3cmd --access_key "0555b35654ad1656d804" 	  --secret_key "h7GhxuBLTrlhVUyxSPUKUV8r/2EI4ngqJxD7iBdBYLhwluN30JaT3Q==" 	  --signature-v2 	  --host=http://localhost:8000 	  --no-ssl 	  --host-bucket="http://localhost:8000/%(bucket)" 	  $@
}
#+end_src

#+RESULTS: env_s3

** Data Gathering and Plotting
#+caption: Utility: Generate table of OSD Ops observed on all objecters at asok
#+name: client_op_table
#+begin_src python -n :var socket="" json_file=0 rm_zero=1 skip_ops=0 :results value table :exports code
import subprocess
import json
from collections import defaultdict
if json_file:
    with open(json_file) as fp:
        out = json.load(fp)
elif socket:
    out = json.loads(subprocess.check_output(\
         f"""
         source {build}/vstart_environment.sh
         cd {build}
         ceph daemon {socket} perf dump
         """,
         shell=True))
else:
    return None
if skip_ops:
    skip_ops = set(skip_ops.split(","))
result=defaultdict(lambda:0)
for objecter in (v for k, v in out.items() if k.startswith("objecter")):
    for k, v in ((k, v) for k, v in objecter.items() if k.startswith("osdop") or k.startswith("omap_")):
        op = k.replace("osdop_", "")
        if op in skip_ops:
            continue
        if (rm_zero and v > 0) or not rm_zero:
            result[op] += v
return result
#+end_src

#+RESULTS: client_op_table
| None |


#+caption: Return admin socket path of running fio process
#+name: fio_asok
#+begin_src bash :noweb yes :results output verbatim
echo -n "asok/client.admin.$(pgrep -f 'fio --').asok"
#+end_src

#+RESULTS: fio_asok
: asok/client.admin..asok

#+caption: Generate a pie plot for table <tab>
#+name: pie_plot
#+begin_src python :var tab="example" :file "./example_pie.svg" :results graphics file value
import matplotlib.pyplot as plt
plt.style.use('tableau-colorblind10')
if tab == "example":
    labels = ["a", "b"]
    sizes = [23, 42]
else:
    labels = [x[0] for x in tab]
    sizes = [x[1] for x in tab]

fig, ax = plt.subplots()
fig.patch.set_alpha(0)
ax.pie(sizes, labels=labels)
ax.patch.set_alpha(0)
return fig
#+end_src

#+RESULTS: pie_plot
[[file:./example_pie.svg]]

** Benchmark Tools

#+name: run_fio
#+begin_src bash :noweb yes :results output file link :var name="none" mix="none" nr_files="128" runtime="10m"
<<env>>
log_file="fio_${name}_${mix}_${run_id}.log"
perf_file="fio_${name}_${mix}_${run_id}_perf.json"
(
    while true; do
	data="$(ceph daemon "$asok/client.admin.$(pgrep -f 'fio --direct').asok" \
		    perf dump 2>/dev/null)"
	if ! [[ -z $data ]]; then
	    echo "$data" > "$perf_file"
	fi
	sleep 1
    done
) &

~/WORKSPACE/fio/fio \
    --direct=1 \
    --rw="$mix" --bs=4k \
    --ioengine=rados --clientname=admin --pool=rbd \
    --conf=$CEPH_CONF \
    --iodepth=8 --nr_files=$nr_files --size=4m \
    --runtime=$runtime --numjobs=1 \
    --time_based --group_reporting \
    --name=throughput-test-job \
    --eta-newline=1 --verify=0 \
    &> "$log_file"

kill %1
wait

echo -n "./${perf_file}"
#+end_src

#+RESULTS: run_fio
[[file:./fio_none_297838a4-5a65-4c97-a708-43f35c4b1f46_perf.json]]

#+name: run_warp
#+begin_src bash :noweb yes :results output file link :var runtime="1m"
<<env>>
<<env_s3>>

log_file="warp_${run_id}.log"
perf_file="warp_${run_id}_perf.json"

podman run --network=host minio/warp mixed \
       --host "127.0.0.1:8000" \
       --access-key "$access_key" \
       --secret-key "$secret_key" \
       --objects 128 \
       --insecure --duration "$runtime" \
       &>"$log_file"


ceph daemon $out/radosgw.8000.asok perf dump 2>/dev/null 1> "$perf_file"

echo -n "./${perf_file}"
#+end_src

#+RESULTS: run_warp
[[file:./warp_297838a4-5a65-4c97-a708-43f35c4b1f46_perf.json]]

* Experiment: RGW Startup
/Restart RGW. Snapshot op and network counters./

Questions:
- What is the RADOS / network cost of restarting an RGW?
- What /type/ of operations are dominant in RGW startup? /read/, /write/, something else?

#+caption: Restart radosgw
#+begin_src bash :noweb yes :results output
<<env>>
exec 2>&1
set -xe
pid=$(pgrep radosgw)
readarray -d "" cmd < /proc/$pid/cmdline
kill $pid
waitpid $pid
"${cmd[@]}"
#+end_src

#+RESULTS:
: ++ pgrep radosgw
: + pid=798452
: + readarray -d '' cmd
: + kill 798452
: + waitpid 798452
: + /compile2/ceph/wip/build/bin/radosgw -c /compile2/ceph/wip/build/ceph.conf --log-file=/compile2/ceph/wip/build/out/radosgw.8000.log --admin-socket=/compile2/ceph/wip/build/out/radosgw.8000.asok --pid-file=/compile2/ceph/wip/build/out/radosgw.8000.pid --rgw_luarocks_location=/compile2/ceph/wip/build/out/radosgw.8000.luarocks -n client.rgw.8000 '--rgw_frontends=beast port=8000'
: 2024-11-30T15:47:41.566+0100 7f730603dbc0 -1 WARNING: all dangerous and experimental features are enabled.
: 2024-11-30T15:47:41.579+0100 7f730603dbc0 -1 WARNING: all dangerous and experimental features are enabled.

Let's see if there were S3 operations already (there should not):

#+begin_src bash :noweb yes :results output
<<env>>
ceph daemon $out/radosgw.8000.asok perf dump rgw | jq '.rgw | with_entries(select(.key | test(".*(req|qlen).*")))'
ceph daemon $out/radosgw.8000.asok perf dump rgw_op | jq '.rgw_op | with_entries(select(.key | test(".*(put|get).*(ops|bytes).*")))'
#+end_src

#+RESULTS:
#+begin_example
{
  "req": 0,
  "failed_req": 0,
  "qlen": 0
}
{
  "put_obj_ops": 0,
  "put_obj_bytes": 0,
  "get_obj_ops": 0,
  "get_obj_bytes": 0
}
#+end_example

Now get RADOS operations counted since start:

#+CALL: client_op_table[:results value table](socket="out/radosgw.8000.asok")

#+name: rgw_startup_osdops
#+RESULTS:
| read   | 17 |
| call   |  9 |
| create |  9 |
| watch  |  9 |
| other  | 32 |

#+CALL: pie_plot[:file "./rgw_startup_osdops.svg"](tab=rgw_startup_osdops)

#+RESULTS:
[[file:./rgw_startup_osdops.svg]]

Looking at the =perf dump= we see 3 messenger entries. One for each worker. A worker is it's own event loop. The messenger distributes connections between them.

#+begin_src bash :noweb yes :results output
<<env>>
ceph daemon $out/radosgw.8000.asok perf dump | \
    jq '(.["AsyncMessenger::Worker-0"], .["AsyncMessenger::Worker-1"], .["AsyncMessenger::Worker-2"]) |
            with_entries(select(.key | test(".*_(messages|bytes)$")))'
#+end_src

#+RESULTS:
#+begin_example
{
  "msgr_recv_messages": 67,
  "msgr_send_messages": 66,
  "msgr_recv_bytes": 136830,
  "msgr_send_bytes": 22659,
  "msgr_recv_encrypted_bytes": 118256,
  "msgr_send_encrypted_bytes": 1568
}
{
  "msgr_recv_messages": 46,
  "msgr_send_messages": 52,
  "msgr_recv_bytes": 17494,
  "msgr_send_bytes": 105134,
  "msgr_recv_encrypted_bytes": 144,
  "msgr_send_encrypted_bytes": 86592
}
{
  "msgr_recv_messages": 49,
  "msgr_send_messages": 51,
  "msgr_recv_bytes": 73769,
  "msgr_send_bytes": 17300,
  "msgr_recv_encrypted_bytes": 59824,
  "msgr_send_encrypted_bytes": 928
}
#+end_example

** Full list of all operations
#+CALL: client_op_table[:results value table](socket="out/radosgw.8000.asok", rm_zero=0)

#+RESULTS:
| stat         |   0 |
| create       |  41 |
| read         |  18 |
| write        |   0 |
| writefull    |   0 |
| writesame    |   0 |
| append       |   0 |
| zero         |   0 |
| truncate     |   0 |
| delete       |   0 |
| mapext       |   0 |
| sparse_read  |   0 |
| clonerange   |   0 |
| getxattr     |   0 |
| setxattr     |   0 |
| cmpxattr     |   0 |
| rmxattr      |   0 |
| resetxattrs  |   0 |
| call         | 120 |
| watch        |  10 |
| notify       |   0 |
| src_cmpxattr |   0 |
| pgls         |   0 |
| pgls_filter  |   0 |
| other        |  64 |
| omap_wr      |   0 |
| omap_rd      |   1 |
| omap_del     |   0 |

* Experiment: S3 PUT
/Run a simple S3 PUT on an otherwise empty bucket. Query op and messenger counters/

Questions:
- What besides storing the use data happens?
- How much overhead in terms of ops and bytes is a 4MB PUT?

** Perf Counters
- =objecter=
  - =.osdop_*=,
  - =.omap_*=
- =AsyncMessenger::Worker-*=
  - =msgr_recv_messages=
  - =msgr_send_messages=
  - =msgr_recv_bytes=
  - =msgr_send_bytes=
  - =msgr_recv_encrypted_bytes=
  - =msgr_send_encrypted_bytes=
- =osd=
  - =op=
  - =op_in_bytes=
  - =op_out_bytes=
  - =subop=
  - =subop_in_bytes=
- =bluestore=
  - =omap_{iterator|rmkeys|rmkey_range|setheader|setkeys}_count=

** Set up bucket
#+caption: Create bucket
#+begin_src bash :noweb yes :results output discard
<<env>>
<<env_s3>>
#s3 mb s3://testbucket
#+end_src

#+RESULTS:

Double check op counters. They should be zero.

#+begin_src bash :noweb yes :results output verbatim
<<env>>
ceph daemon $out/radosgw.8000.asok perf dump | jq '.[] | with_entries(select((.key | test("^(osdop|omap)_")) and (.value > 0) )) | select(length > 0)'
#+end_src

#+RESULTS:

** S3 PUT; Collect Perf Counters
We run an S3 PUT using =s3cmd= and right afterwards collect =perf dump=

#+caption: (1) S3 PUT operation (2) Get non-zero RADOS operation counter
#+begin_src bash :noweb yes :results output verbatim
set -x
<<env>>
<<env_s3>>
<<testfile>>
<<reset_fns>>

(sudo python3 -u ./radostrace.py $(pgrep radosgw) > "rgw_put_radostrace.log") &
sleep 5
reset_rgw_perf_counters
reset_daemon_perf_counters
s3 put $(testfile_4mb) s3://testbucket/$RANDOM | tr -d "\r"
ceph daemon $out/radosgw.8000.asok perf dump > "rgw_put_perf.json"
jq '.[] | with_entries(select((.key | test("^(osdop|omap)_")) and (.value > 0) )) | select(length > 0)' "rgw_put_perf.json"
sleep 5
kill %1
wait
#+end_src

#+RESULTS:
#+begin_example
{
    "success": "perf reset all"
}
upload: '/tmp/random_4mb' -> 's3://testbucket/30641'  [1 of 1]
   65536 of 4194304     1% in    0s    15.29 MB/s 4194304 of 4194304   100% in    0s    48.78 MB/s  done
{
  "osdop_stat": 2,
  "osdop_create": 1,
  "osdop_writefull": 1,
  "osdop_setxattr": 9,
  "osdop_call": 5
}
#+end_example

=s3cmd= returned success. We collected the stats. We now also check the logs for the entry that RGW prints
after finishing an operation. This also gives us the latency number for that individual operation.

#+caption: Get the RGW log line with our recent PUT
#+begin_src bash :noweb yes :results output verbatim
<<env>>
tac $out/radosgw.8000.log | grep -E -m1 'beast:.*PUT /testbucket'
#+end_src

#+RESULTS:
: 2025-01-27T23:32:43.876+0100 7f35ae92b6c0  1 beast: 0x7f34def6b200: ::1 - testid [27/Jan/2025:23:32:43.798 +0100] "PUT /testbucket/30641 HTTP/1.1" 200 4194304 - - - latency=0.077001937s

#+CALL: client_op_table[:results value table](json_file="rgw_put_perf.json", skip_ops="watch")

#+name: rgw_put_osdops
#+RESULTS:
| stat      | 2 |
| create    | 1 |
| writefull | 1 |
| setxattr  | 9 |
| call      | 5 |

#+CALL: pie_plot[:file "./rgw_put_osdops.svg"](tab=rgw_put_osdops)

#+RESULTS:
[[file:./rgw_put_osdops.svg]]

#+caption: Get the operation counter
#+name: get_num_op_s3_put
#+begin_src bash :noweb yes :results output verbatim
<<env>>
jq '[.[] | .op] | add' "rgw_put_perf.json"
#+end_src

#+RESULTS: get_num_op_s3_put
: 3

The =op= counter is not the same as the sum of the =osdop= counters

#+caption: Sum all osd operations
#+name: get_num_osdop_s3_put
#+begin_src bash :noweb yes :results output verbatim
<<env>>
jq '[.[] | with_entries(select(.key | test ("^(osdop|omap)_"))) | .[] ] | add' "rgw_put_perf.json"
#+end_src

#+RESULTS: get_num_osdop_s3_put
: 18

#+caption: Get messenger perf counters
#+begin_src bash :noweb yes :results output verbatim
<<env>>
jq 'reduce ((."AsyncMessenger::Worker-0", ."AsyncMessenger::Worker-1", ."AsyncMessenger::Worker-2")
             | to_entries[]
	       | select(.key | test("_(messages|bytes)$")))
        as {$key, $value} ({}; .[$key] += $value)' "rgw_put_perf.json"
#+end_src

#+RESULTS:
: {
:   "msgr_recv_messages": 3,
:   "msgr_send_messages": 3,
:   "msgr_recv_bytes": 1481,
:   "msgr_send_bytes": 4197648,
:   "msgr_recv_encrypted_bytes": 0,
:   "msgr_send_encrypted_bytes": 0
: }

#+caption: Get the number of sent messages
#+name: get_num_send_messages
#+begin_src bash :noweb yes :results output verbatim
<<env>>
jq '[."AsyncMessenger::Worker-0", ."AsyncMessenger::Worker-1", ."AsyncMessenger::Worker-2"] | map(.msgr_send_messages) | add' "rgw_put_perf.json"
#+end_src

#+RESULTS: get_num_send_messages
: 3

#+caption: Calculate message overhead from send bytes vs. 4MB PUT
#+name: get_sent_overhead
#+begin_src bash :noweb yes :results output verbatim
<<env>>
sent=$(jq '[."AsyncMessenger::Worker-0", ."AsyncMessenger::Worker-1", ."AsyncMessenger::Worker-2"] | map(.msgr_send_bytes) | add' "rgw_put_perf.json")
sz_4mb=$((4*1024*1024))
overhead=$(($sent - $sz_4mb))
echo $overhead
#+end_src

#+RESULTS: get_sent_overhead
: 3344

** Analysis

We saw:
- A sum of call_get_num_osdop_s3_put() {{{results(=28=)}}} OSD Ops
- The op counter reported call_get_num_op_s3_put() {{{results(=13=)}}} OSD Ops.
-  call_get_num_send_messages() {{{results(=18=)}}} messages sent by the messenger.

At first the difference between op counter and sum of ops might be strange, but in RADOS an Operation may consists of many combined Operations. They can even depend on each other to build things like conditional writes (a version assert followed by a write).

We also learn that a PUT is not just a write. There is metadata (setxattr) and data structures (call ops) to update as well.

Our overhead in bytes: call_get_sent_overhead() {{{results(=8282=)}}}.

** RADOS Op Trace
#+begin_src bash :noweb yes :results output table
grep -E -v "(^tracing|watch ping cookie)" "rgw_put_radostrace.log"
#+end_src

#+RESULTS:
| [       424] | .dir.903d2ae0-8d7f-4edc-b65d-e3abe1732c23.4484.2.5 | stat → call rgw.guard_bucket_resharding in=36b → call rgw.bucket_prepare_op in=217b                                                                                                                                                                                                                                                                                             |   | 21.00ms |
| [       425] | 903d2ae0-8d7f-4edc-b65d-e3abe1732c23.4484.2_29332  | create → setxattr user.rgw.idtag (62) in=76b → setxattr user.rgw.tail_tag (62) in=79b → writefull 0~4194304 in=4194304b → setxattr user.rgw.manifest (351) in=368b → setxattr user.rgw.acl (147) in=159b → setxattr user.rgw.content_type (25) in=46b → setxattr user.rgw.etag (32) in=45b → setxattr user.rgw.x-amz-meta-s3cmd-attrs (139) in=170b → call rgw.obj_store_pg_ver |   | 48.55ms |
| [       426] | .dir.903d2ae0-8d7f-4edc-b65d-e3abe1732c23.4484.2.5 | stat → call rgw.guard_bucket_resharding in=36b → call rgw.bucket_complete_op in=373b                                                                                                                                                                                                                                                                                            |   | 28.56ms |
| [       437] | queues_list_object                                 | omap-get-keys in=12b                                                                                                                                                                                                                                                                                                                                                            |   | 0.63ms  |

** Bonus: Messenger Connections
Question: Where is my RadosGW connected to?

*Requires a change that is not in upstream*

#+begin_src bash :noweb yes :results output
<<env>>
for msgr in $(ceph daemon $out/radosgw.8000.asok messenger dump \
		  | jq -r '.messengers | @tsv'); do
    ceph daemon $out/radosgw.8000.asok messenger dump $msgr
done \
    | jq -r '.messenger.connections[].async_connection |
             select(.state == "STATE_CONNECTION_ESTABLISHED") |
             "\(.target_addr.addr) \t \(.peer.type) \t id:\(.peer.id) gid:\(.peer.global_id)"'
#+end_src

#+RESULTS:
#+begin_example
192.168.101.23:6800 	 mgr 	 id:-1 gid:0
192.168.101.23:6802 	 osd 	 id:-1 gid:0
192.168.101.23:6810 	 osd 	 id:-1 gid:0
192.168.101.23:40393 	 mon 	 id:-1 gid:0
192.168.101.23:6800 	 mgr 	 id:-1 gid:0
192.168.101.23:6802 	 osd 	 id:-1 gid:0
192.168.101.23:6810 	 osd 	 id:-1 gid:0
192.168.101.23:6818 	 osd 	 id:-1 gid:0
192.168.101.23:40391 	 mon 	 id:-1 gid:0
192.168.101.23:6800 	 mgr 	 id:-1 gid:0
192.168.101.23:40393 	 mon 	 id:-1 gid:0
#+end_example

/For some reason the librados messenger doesn't set the peer ids/

** OSD: Messenger and Op Processing
Ceph distributed data across its many OSDs.
In our sample cluster we have only 3 OSDs.

Questions:
- Does the S3 PUT go to all OSDs
- How distributed are the operations. Are there hot spots?
- Where did the data go? Can we follow the replication somehow?


#+caption: Get messenger perf counters of all OSDs in the cluster
#+begin_src bash :noweb yes :results output verbatim
<<env>>
<<get_daemons>>
for osd in $(osds); do
    echo $osd
    ceph tell $osd perf dump 2>/dev/null | \
    jq 'reduce ((."AsyncMessenger::Worker-0", ."AsyncMessenger::Worker-1", ."AsyncMessenger::Worker-2")
             | to_entries[]
	       | select(.key | test("_(messages|bytes)$")))
        as {$key, $value} ({}; .[$key] += $value)'
done
#+end_src

#+RESULTS:
#+begin_example
osd.0
{
  "msgr_recv_messages": 711,
  "msgr_send_messages": 713,
  "msgr_recv_bytes": 4345123,
  "msgr_send_bytes": 8789456,
  "msgr_recv_encrypted_bytes": 0,
  "msgr_send_encrypted_bytes": 216896
}
osd.1
{
  "msgr_recv_messages": 671,
  "msgr_send_messages": 675,
  "msgr_recv_bytes": 4343967,
  "msgr_send_bytes": 470602,
  "msgr_recv_encrypted_bytes": 0,
  "msgr_send_encrypted_bytes": 295632
}
osd.2
{
  "msgr_recv_messages": 656,
  "msgr_send_messages": 658,
  "msgr_recv_bytes": 4351558,
  "msgr_send_bytes": 373538,
  "msgr_recv_encrypted_bytes": 0,
  "msgr_send_encrypted_bytes": 180096
}
#+end_example

#+caption: Get OSD op and subop counters for all OSDs in the cluster
#+begin_src bash :noweb yes :results output verbatim
<<env>>
<<get_daemons>>
for osd in $(osds); do
    echo $osd
    ceph tell $osd perf dump 2>/dev/null | \
    jq '.osd | with_entries(select(.key | test("^(op|op_(in|out)_bytes|subop|subop_in_bytes)$")))'
done
#+end_src

#+RESULTS:
#+begin_example
osd.0
{
  "op": 16,
  "op_in_bytes": 4194304,
  "op_out_bytes": 0,
  "subop": 2,
  "subop_in_bytes": 2064
}
osd.1
{
  "op": 6,
  "op_in_bytes": 0,
  "op_out_bytes": 0,
  "subop": 3,
  "subop_in_bytes": 4198251
}
osd.2
{
  "op": 11,
  "op_in_bytes": 0,
  "op_out_bytes": 0,
  "subop": 1,
  "subop_in_bytes": 4196187
}
#+end_example


Result:
The operations land on all OSDs.
One OSD received the 4MB data (=op_in_bytes=) and sent it to the others (=subop_in_bytes=)
Load was more or less distributed equally between the nodes. In fact every stored the user data at the end

** Bluestore: OMaps
#+caption: Get bluestore omap counters
#+begin_src bash :noweb yes :results output verbatim
<<env>>
<<get_daemons>>
for osd in $(osds); do
    ceph tell $osd perf dump 2>/dev/null
done \
    | jq '.bluestore | with_entries(select(.key | test("^omap_.*_count$")))'
#+end_src

#+RESULTS:
#+begin_example
{
  "omap_iterator_count": 0,
  "omap_rmkeys_count": 0,
  "omap_rmkey_range_count": 0,
  "omap_setheader_count": 1,
  "omap_setkeys_count": 5
}
{
  "omap_iterator_count": 0,
  "omap_rmkeys_count": 0,
  "omap_rmkey_range_count": 0,
  "omap_setheader_count": 1,
  "omap_setkeys_count": 5
}
{
  "omap_iterator_count": 0,
  "omap_rmkeys_count": 0,
  "omap_rmkey_range_count": 0,
  "omap_setheader_count": 1,
  "omap_setkeys_count": 5
}
#+end_example

We can drill down a little further and ask Bluestore how many OMAP accesses it saw.
These are likely originate from =call='s.

At this point most perf counters are more focused on latency than counting operations.

** What can we learn from looking at counters?
- Test assumptions on what high-level operations are to the RADOS cluster. For example in integration tests
- Take the time derivative to look at the rate
- Understand the operation mix handled by the cluster. Is it write heavy? read heavy? Is it what it was designed for?
- Give context to latency metrics that often give the latency for many operations combined
- Analyze cluster for bursty operations during specific times

* Experiment: Simple Write Latency
/Run simple write benchmark. Learn about latency metrics/

** Perf Counters
- =objecter.op_latency=
- =AsyncMessenger*.msgr_send_messages_queue_lat=
- =osd.op_latency.avgtime=
- =osd.subop_latency.avgtime=
** Setup
The workload is a simple random write workload using =fio=
- 4k write
- 1024 objects each sized 4M
- IO queue depth 8
- RADOS IO engine

#+caption: Reset counters
#+begin_src bash :noweb yes :results output verbatim :async :session fio
<<reset_fns>>
reset_daemon_perf_counters
#+end_src

#+RESULTS:

#+caption: Run fio, capture librados perf counters
#+CALL: run_fio(name="simple", mix="randwrite", nr_files="128", runtime="1m")

#+name: fio_simple_write
#+RESULTS:
[[file:./fio_simple_randwrite_297838a4-5a65-4c97-a708-43f35c4b1f46_perf.json]]

#+caption: Capture OSD perf counters
#+begin_src bash :noweb yes :results output discard
<<env>>
<<get_daemons>>
for osd in $(osds); do
    ceph tell "$osd" perf dump 2>/dev/null 1>"fio_simple_${run_id}_${osd}_perf.json"
done
#+end_src

#+RESULTS:

** Latency at =fio='s librados

#+caption: Get objecter and messenger latencies
#+begin_src bash :noweb yes :results output verbatim :var perf=fio_simple_write
echo "objecter"
jq '.objecter.op_latency' "$perf"
echo "messenger"
jq '[."AsyncMessenger::Worker-0", ."AsyncMessenger::Worker-1", ."AsyncMessenger::Worker-2"] | map(.msgr_send_messages_queue_lat)' "$perf"
#+end_src

#+RESULTS:
#+begin_example
objecter
{
  "avgcount": 10153,
  "sum": 474.325235709,
  "avgtime": 0.046717742
}
messenger
[
  {
    "avgcount": 3256,
    "sum": 0.105244073,
    "avgtime": 0.000032323
  },
  {
    "avgcount": 3969,
    "sum": 0.129336836,
    "avgtime": 0.000032586
  },
  {
    "avgcount": 2942,
    "sum": 0.092894762,
    "avgtime": 0.000031575
  }
]
#+end_example

Double check our operation mix. It is indeed only writes.

#+CALL: client_op_table(json_file=fio_simple_write)

#+RESULTS:
| write | 10161 |

We don't find may counters about latency on the RADOS client side.
The most interesting one is =op_latency= that captures Objecter operations.

There is also =msgr_send_messages_queue_lat= which measures the time a message spends in the sent queue.
In our case this is very low - there is not waiting to go out to the network.

** OSD =op_latency=
On the OSD side we find =op_latency= and variants for read, write and read/write operations.
We look at the one that combines everything since we know our operation mix (only writes).

#+caption: Get OSD op latency from all cluster OSDs
#+begin_src bash :noweb yes :results output verbatim table
<<env>>
<<get_daemons>>
echo "target op_latency"
for osd in $(osds); do
    echo -n "$osd "
    jq '.osd.op_latency.avgtime' < "fio_simple_${run_id}_${osd}_perf.json"
done
#+end_src

#+RESULTS:
| target |  op_latency |
| osd.0  | 0.042992129 |
| osd.1  | 0.044089243 |
| osd.2  | 0.043497355 |

That is almost what we saw on the client.
Not surprising, since the cluster runs on localhost.
There is almost no network delay.

** OSD Replication
Q: What part does replication play?

#+caption: Get op_latency and subop_latency from all OSDs
#+begin_src bash :noweb yes :results output table
<<env>>
<<get_daemons>>
echo "target op_latency subop_latency op-subop"
for osd in $(osds); do
    echo -n "$osd "
    jq -r '[.osd.op_latency.avgtime, .osd.subop_latency.avgtime, .osd.op_latency.avgtime - .osd.subop_latency.avgtime] | @tsv' < "fio_simple_${run_id}_${osd}_perf.json"
done
#+end_src

#+RESULTS:
| target |  op_latency | subop_latency |              op-subop |
| osd.0  | 0.042992129 |   0.037055554 | 0.0059365749999999995 |
| osd.1  | 0.044089243 |   0.037899561 |  0.006189682000000002 |
| osd.2  | 0.043497355 |   0.038258205 |  0.005239149999999998 |

=op_latency= includes =subop_latency=.
Subtracting both gives us about 1ms.

* Experiment: Operation Mix
/Average op latency must be controlled for operation mix/

Run three distinct workloads. Get the op_latencies.


#+CALL: run_fio(name="opmix", mix="randwrite", nr_files="128", runtime="1m")

#+name: fio_mix_randwrite
#+RESULTS:
[[file:./fio_opmix_randwrite_297838a4-5a65-4c97-a708-43f35c4b1f46_perf.json]]

#+CALL: run_fio(name="opmix", mix="rw", nr_files="128", runtime="1m")

#+name: fio_mix_rw
#+RESULTS:
[[file:./fio_opmix_rw_297838a4-5a65-4c97-a708-43f35c4b1f46_perf.json]]


#+CALL: run_fio(name="opmix", mix="randread", nr_files="128", runtime="1m")

#+name: fio_mix_randread
#+RESULTS:
[[file:./fio_opmix_randread_297838a4-5a65-4c97-a708-43f35c4b1f46_perf.json]]

#+begin_src bash :results output table :var randread=fio_mix_randread rw=fio_mix_rw randwrite=fio_mix_randwrite
paste \
    <(echo -e 'randread\nrw\nrandwrite') \
    <(jq '.objecter.op_latency.avgtime*1000' $randread $rw $randwrite)
#+end_src

#+RESULTS:
| randread  |   0.52078 |
| rw        | 29.578085 |
| randwrite | 46.274006 |

A trivial result, right?

Reads are faster than writes and a mix of both is somewhere in the middle.

This is however not the point :). The point is that operation averages can be deceiving. They are *very*
dependent on the mix of operations. Operations take vastly different times and have different size.

The same cluster serving RBD may have vastly different average latency reported than on metadata heavy RGW.
Client operations like S3 PUTs are never just a single write. They are a mix of a dozen operations.

The same goes for looking at average latency over time.
If the workload changed as well it doesn't right away mean that the cluster got slow with age.

* Experiment: S3 Benchmark
/Run a mixed S3 workload, analyze the op mix and introduce histograms/

** Set up bucket; Reset metrics
#+caption: Create bucket and reset performance counters
#+begin_src bash :noweb yes :results output discard
<<env>>
<<env_s3>>
<<reset_fns>>
s3 mb s3://testbucket
reset_rgw_perf_counters
reset_daemon_perf_counters
#+end_src

#+RESULTS:

#+begin_src bash :noweb yes :results output verbatim
<<env>>
ceph daemon $out/radosgw.8000.asok perf dump | jq '.[] | with_entries(select((.key | test("^(osdop|omap)_")) and (.value > 0) )) | select(length > 0)'
#+end_src

#+RESULTS:

** S3 Benchmark: =warp= mixed
We run =warp=, collect the results and fetch the perf counters from RGW.

#+CALL: run_warp(runtime="1m")

#+name: rgw_s3_bench_perf
#+RESULTS:
[[file:./warp_297838a4-5a65-4c97-a708-43f35c4b1f46_perf.json]]

#+caption: Get benchmark stats from warp log
#+begin_src bash :var perf=rgw_s3_bench_perf :results output verbatim
run_id="$(sed -e 's/.*warp_\(.*\)_perf.*/\1/g' <<< "$perf")"
grep -E "(Operation|Cluster Total|Throughput)" "warp_${run_id}.log"
#+end_src

#+RESULTS:
: Operation: DELETE, 10%, Concurrency: 20, Ran 59s.
:  * Throughput: 21.97 obj/s
: Operation: GET, 45%, Concurrency: 20, Ran 59s.
:  * Throughput: 981.65 MiB/s, 98.17 obj/s
: Operation: PUT, 15%, Concurrency: 20, Ran 59s.
:  * Throughput: 326.52 MiB/s, 32.65 obj/s
: Operation: STAT, 30%, Concurrency: 20, Ran 59s.
:  * Throughput: 65.70 obj/s
: Cluster Total: 1307.39 MiB/s, 218.31 obj/s over 59s.

#+caption: collect osd metrics
#+begin_src bash :var perf=rgw_s3_bench_perf :results output verbatim :noweb yes
<<env>>
<<get_daemons>>
run_id="$(sed -e 's/.*warp_\(.*\)_perf.*/\1/g' <<< "$perf")"
for osd in $(osds); do
    ceph tell "$osd" perf dump 2>/dev/null 1> "warp_${run_id}_${osd}_perf.json"
    ceph tell "$osd" perf histogram dump 2>/dev/null 1> "warp_${run_id}_${osd}_hist.json"
done
#+end_src

#+RESULTS:


** Client Operations
#+CALL: client_op_table[:results value table](json_file=rgw_s3_bench_perf)

#+name: rgw_s3_bench_osdops
#+RESULTS:
| stat      | 20409 |
| create    |  2111 |
| read      | 17797 |
| writefull |  6333 |
| setxattr  | 16888 |
| cmpxattr  |  2111 |
| call      | 37615 |
| watch     |   150 |
| other     | 16187 |
| omap_rd   |     2 |

#+CALL: pie_plot[:file "./rgw_warp_osdops.svg"](tab=rgw_s3_bench_osdops)

#+RESULTS:
[[file:./rgw_warp_osdops.svg]]

#+caption: Get messenger counter from RGW
#+begin_src bash :noweb yes :results output verbatim :var perf=rgw_s3_bench_perf
<<env>>
jq 'reduce ((."AsyncMessenger::Worker-0", ."AsyncMessenger::Worker-1", ."AsyncMessenger::Worker-2")
             | to_entries[]
	       | select(.key | test("_(messages|bytes)$")))
        as {$key, $value} ({}; .[$key] += $value)' "$perf"
#+end_src

#+RESULTS:
: {
:   "msgr_recv_messages": 43295,
:   "msgr_send_messages": 43355,
:   "msgr_recv_bytes": 62041669362,
:   "msgr_send_bytes": 22053219662,
:   "msgr_recv_encrypted_bytes": 0,
:   "msgr_send_encrypted_bytes": 11504
: }

#+caption: Get op latency counter from objecter
#+begin_src bash :noweb yes :results output table :var perf=rgw_s3_bench_perf
jq -r 'to_entries | map(select(.key | test("^objecter"))) | .[] | [.key, .value.op_latency.avgtime] | @tsv' "$perf"
#+end_src

#+RESULTS:
| objecter            |         0.0 |
| objecter-0x2639a340 |         0.0 |
| objecter-0x2639add0 | 0.043418261 |

** OSD
#+caption: Get OSD latency counters
#+begin_src bash :noweb yes :results output verbatim table :var perf=rgw_s3_bench_perf
<<env>>
<<get_daemons>>
run_id="$(sed -e 's/.*warp_\(.*\)_perf.*/\1/g' <<< "$perf")"
echo "target op_latency op_r_latency op_w_latency op_rw_latency"
for osd in $(osds); do
    echo -n "$osd "
    jq -r '[.osd.op_latency.avgtime, .osd.op_r_latency.avgtime, .osd.op_w_latency.avgtime, .osd.op_rw_latency.avgtime] | @tsv ' \
       < "warp_${run_id}_${osd}_perf.json"
done
#+end_src

#+RESULTS:
| target |  op_latency | op_r_latency | op_w_latency | op_rw_latency |
| osd.0  | 0.041201573 |  0.005672571 |  0.099334064 |   0.083447218 |
| osd.1  | 0.044812809 |  0.005676555 |  0.098463874 |   0.082343773 |
| osd.2  | 0.039115449 |  0.005419339 |  0.098269827 |   0.082073632 |

** OSD Latency Histograms
#+caption: Get OSD op histograms
#+begin_src bash :noweb yes :results output table
<<env>>
ceph tell osd.0 perf histogram schema 2>/dev/null | jq -r '.osd | to_entries | .[] | [.key, .value.description] | @csv' | grep -v scrub
#+end_src

#+RESULTS:
| op_r_latency_out_bytes_histogram  | Histogram of operation latency (including queue time) + data read       |
| op_w_latency_in_bytes_histogram   | Histogram of operation latency (including queue time) + data written    |
| op_rw_latency_in_bytes_histogram  | Histogram of rw operation latency (including queue time) + data written |
| op_rw_latency_out_bytes_histogram | Histogram of rw operation latency (including queue time) + data read    |

The =op_..= histograms and =op_latency= time average all count the same latency number.

They differ in (1) when they count:
- =op_latency= :: every operation
- =op_r_latency_out_bytes= :: =op.may_read()=
- =op_w_latency_in_bytes= :: =op.may_write() || op.may_cache()=
- =op_rw_latency_in_bytes= and =op_rw_latency_out_bytes= :: =op.may_read() && op.may_write=

And (2) what number of bytes they count.
- =in_bytes= count =ctx->bytes_written=
- =out_bytes= count =ctx->bytes_read=

(see =void PrimaryLogPG::log_op_stats(const OpRequest& op, const uint64_t inb, const uint64_t outb)=)

*** 1D: latency buckets

#+caption: OSD histograms as one dimensional (latency)
#+begin_src bash :noweb yes :results output table :var perf=rgw_s3_bench_perf
run_id="$(sed -e 's/.*warp_\(.*\)_perf.*/\1/g' <<< "$perf")"
echo -e 'bucket\trw in\trw out\tread out\twrite in'
paste <(jq -r ".osd.op_rw_latency_in_bytes_histogram" < "warp_${run_id}_osd.0_hist.json" \
              | ./perf_hist_dump.py 1d) \
      <(jq -r ".osd.op_rw_latency_out_bytes_histogram" < "warp_${run_id}_osd.0_hist.json" \
            | ./perf_hist_dump.py 1d | cut -f 2) \
      <(jq -r ".osd.op_r_latency_out_bytes_histogram" < "warp_${run_id}_osd.0_hist.json" \
            | ./perf_hist_dump.py 1d | cut -f 2) \
      <(jq -r ".osd.op_w_latency_in_bytes_histogram" < "warp_${run_id}_osd.0_hist.json" \
            | ./perf_hist_dump.py 1d | cut -f 2)
#+end_src

#+RESULTS:
| bucket        | rw in | rw out | read out | write in |
| <0            |     0 |      0 |        0 |        0 |
| 0ns…99µs      |     0 |      0 |        0 |        0 |
| 100µs…199µs   |     0 |      0 |       20 |        0 |
| 200µs…399µs   |     0 |      0 |     1817 |        0 |
| 400µs…799µs   |     0 |      0 |     1220 |        0 |
| 800µs…1ms     |     0 |      0 |      248 |        0 |
| 1ms…3ms       |     0 |      0 |      719 |        0 |
| 3ms…6ms       |     0 |      0 |     1732 |        0 |
| 6ms…12ms      |     0 |      0 |     1373 |        0 |
| 12ms…25ms     |     0 |      0 |      630 |        0 |
| 25ms…51ms     |   679 |    679 |      176 |        6 |
| 51ms…102ms    |  2225 |   2225 |       44 |     1302 |
| 102ms…204ms   |   849 |    849 |       12 |      817 |
| 204ms…409ms   |    31 |     31 |        0 |        9 |
| 409ms…819ms   |     0 |      0 |        0 |        0 |
| 819ms…1s      |     0 |      0 |        0 |        0 |
| 1s…3s         |     0 |      0 |        0 |        0 |
| 3s…6s         |     0 |      0 |        0 |        0 |
| 6s…13s        |     0 |      0 |        0 |        0 |
| 13s…26s       |     0 |      0 |        0 |        0 |
| 26s…52s       |     0 |      0 |        0 |        0 |
| 52s…104s      |     0 |      0 |        0 |        0 |
| 104s…209s     |     0 |      0 |        0 |        0 |
| 209s…419s     |     0 |      0 |        0 |        0 |
| 419s…838s     |     0 |      0 |        0 |        0 |
| 838s…1677s    |     0 |      0 |        0 |        0 |
| 1677s…3355s   |     0 |      0 |        0 |        0 |
| 3355s…6710s   |     0 |      0 |        0 |        0 |
| 6710s…13421s  |     0 |      0 |        0 |        0 |
| 13421s…26843s |     0 |      0 |        0 |        0 |
| 26843s…53687s |     0 |      0 |        0 |        0 |
| >53687s       |     0 |      0 |        0 |        0 |

Very interesting!

We see that:
- fast reads dominate the count
- rw in and rw out are the same, as they differ only in the bytes dimension

*** 2D: latency ❌ bytes
#+caption: OSD 0 write latency histogram matrix latency ❌ bytes
#+begin_src bash :noweb yes :results output table :var perf=rgw_s3_bench_perf
run_id="$(sed -e 's/.*warp_\(.*\)_perf.*/\1/g' <<< "$perf")"
jq -r ".osd.op_w_latency_in_bytes_histogram" < "warp_${run_id}_osd.0_hist.json" \
    | ./perf_hist_dump.py 2d
#+end_src

#+RESULTS:
| ⬔          | 0…511 | 512…1023 | 1K…2K | 2K…4K | 4K…8K | 8K…16K | 16K…32K | 32K…64K | 64K…128K | 128K…256K | 256K…512K | 512K…1024K | 1M…2M | 2M…4M | 4M…8M | 8M…16M | 16M…32M | >32M |
| <0          |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 0ns…99µs    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 100µs…199µs |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 200µs…399µs |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 400µs…799µs |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 800µs…1ms   |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 1ms…3ms     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 3ms…6ms     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 6ms…12ms    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 12ms…25ms   |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 25ms…51ms   |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     2 |     4 |      0 |       0 |    0 |
| 51ms…102ms  |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |   461 |   841 |      0 |       0 |    0 |
| 102ms…204ms |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |   268 |   549 |      0 |       0 |    0 |
| 204ms…409ms |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     1 |     8 |      0 |       0 |    0 |
| 409ms…819ms |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 819ms…1s    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 1s…3s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 3s…6s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 6s…13s      |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 13s…26s     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 26s…52s     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| >104s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |

#+caption: OSD 0 read latency histogram matrix latency ❌ bytes
#+begin_src bash :noweb yes :results output table :var perf=rgw_s3_bench_perf
run_id="$(sed -e 's/.*warp_\(.*\)_perf.*/\1/g' <<< "$perf")"
jq -r ".osd.op_r_latency_out_bytes_histogram" < "warp_${run_id}_osd.0_hist.json" \
    | ./perf_hist_dump.py 2d
#+end_src

#+RESULTS:
| ⬔          | 0…511 | 512…1023 | 1K…2K | 2K…4K | 4K…8K | 8K…16K | 16K…32K | 32K…64K | 64K…128K | 128K…256K | 256K…512K | 512K…1024K | 1M…2M | 2M…4M | 4M…8M | 8M…16M | 16M…32M | >32M |
| <0          |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 0ns…99µs    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 100µs…199µs |     0 |       20 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 200µs…399µs |    31 |     1421 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |   333 |    32 |      0 |       0 |    0 |
| 400µs…799µs |    45 |      413 |     9 |     1 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |   185 |   567 |      0 |       0 |    0 |
| 800µs…1ms   |    17 |       39 |    26 |     3 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |    59 |   104 |      0 |       0 |    0 |
| 1ms…3ms     |     3 |       21 |     5 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |   382 |   308 |      0 |       0 |    0 |
| 3ms…6ms     |     1 |       33 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |   530 |  1168 |      0 |       0 |    0 |
| 6ms…12ms    |     2 |       38 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |   313 |  1020 |      0 |       0 |    0 |
| 12ms…25ms   |     3 |       26 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |   135 |   466 |      0 |       0 |    0 |
| 25ms…51ms   |     0 |       21 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |    35 |   120 |      0 |       0 |    0 |
| 51ms…102ms  |     0 |        8 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |    10 |    26 |      0 |       0 |    0 |
| 102ms…204ms |     0 |        3 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     2 |     7 |      0 |       0 |    0 |
| 204ms…409ms |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 409ms…819ms |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 819ms…1s    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 1s…3s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 3s…6s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 6s…13s      |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 13s…26s     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 26s…52s     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| >104s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |

#+caption: OSD 0 read/write latency data out histogram matrix latency ❌ bytes
#+begin_src bash :noweb yes :results output table :var perf=rgw_s3_bench_perf
run_id="$(sed -e 's/.*warp_\(.*\)_perf.*/\1/g' <<< "$perf")"
jq -r ".osd.op_rw_latency_out_bytes_histogram" < "warp_${run_id}_osd.0_hist.json" \
    | ./perf_hist_dump.py 2d
#+end_src

#+RESULTS:
| ⬔          | 0…511 | 512…1023 | 1K…2K | 2K…4K | 4K…8K | 8K…16K | 16K…32K | 32K…64K | 64K…128K | 128K…256K | 256K…512K | 512K…1024K | 1M…2M | 2M…4M | 4M…8M | 8M…16M | 16M…32M | >32M |
| <0          |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 0ns…99µs    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 100µs…199µs |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 200µs…399µs |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 400µs…799µs |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 800µs…1ms   |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 1ms…3ms     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 3ms…6ms     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 6ms…12ms    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 12ms…25ms   |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 25ms…51ms   |   679 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 51ms…102ms  |  2225 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 102ms…204ms |   849 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 204ms…409ms |    31 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 409ms…819ms |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 819ms…1s    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 1s…3s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 3s…6s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 6s…13s      |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 13s…26s     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 26s…52s     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| >104s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |

#+caption: OSD 0 read/write latency data in histogram matrix latency ❌ bytes
#+begin_src bash :noweb yes :results output table :var perf=rgw_s3_bench_perf
run_id="$(sed -e 's/.*warp_\(.*\)_perf.*/\1/g' <<< "$perf")"
jq -r ".osd.op_rw_latency_in_bytes_histogram" < "warp_${run_id}_osd.0_hist.json" \
    | ./perf_hist_dump.py 2d
#+end_src

#+RESULTS:
| ⬔          | 0…511 | 512…1023 | 1K…2K | 2K…4K | 4K…8K | 8K…16K | 16K…32K | 32K…64K | 64K…128K | 128K…256K | 256K…512K | 512K…1024K | 1M…2M | 2M…4M | 4M…8M | 8M…16M | 16M…32M | >32M |
| <0          |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 0ns…99µs    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 100µs…199µs |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 200µs…399µs |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 400µs…799µs |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 800µs…1ms   |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 1ms…3ms     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 3ms…6ms     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 6ms…12ms    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 12ms…25ms   |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 25ms…51ms   |   495 |      184 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 51ms…102ms  |  1820 |      405 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 102ms…204ms |   780 |       69 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 204ms…409ms |    31 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 409ms…819ms |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 819ms…1s    |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 1s…3s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 3s…6s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 6s…13s      |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 13s…26s     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| 26s…52s     |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |
| >104s       |     0 |        0 |     0 |     0 |     0 |      0 |       0 |       0 |        0 |         0 |         0 |          0 |     0 |     0 |     0 |      0 |       0 |    0 |


* Misc
** Perf Counter Stats
From running =pcb.py=:
#+begin_quote
Found 880 perf counters in 41 groups
#+end_quote
** Examples of Gauges
#+RESULTS:
#+begin_example
{
  "numpg": 369,
  "numpg_primary": 136,
  "numpg_replica": 233,
  "numpg_stray": 0,
  "numpg_removing": 0,
  "stat_bytes": 108447916032,
  "stat_bytes_used": 1096265728,
  "stat_bytes_avail": 107351650304,
}
#+end_example


* Extra: OSD Perf Queries
/Get the top talking clients/

Start manager module. Register query a query. We get a query id back that we can later fetch counters with.

#+caption: Register osd perf query
#+begin_src bash :noweb yes :results output
<<env>>
ceph mgr module enable osd_perf_query || true
ceph osd perf query add --query=client_id 2>/dev/null
#+end_src

#+name: perf_query_id
#+RESULTS:
: 8

#+caption: Get counters for perf query
#+begin_src bash :noweb yes :var query_id=perf_query_id :results output
<<env>>
ceph osd perf counters get "$query_id" 2>/dev/null
#+end_src

#+RESULTS:
: +--------------+-----------+----------+-----------------+----------------+---------------------+--------------------+
: | CLIENT_ID    |WRITE_OPS  |READ_OPS  |WRITE_BYTES/SEC  |READ_BYTES/SEC  |WRITE_LATENCY(MSEC)  |READ_LATENCY(MSEC)  |
: +--------------+-----------+----------+-----------------+----------------+---------------------+--------------------+
: |client.15437  |    9      |   16     |      3.50       |     0.00       |       14.91         |       5.58         |
: +--------------+-----------+----------+-----------------+----------------+---------------------+--------------------+


* COMMENT org-babel settings
  Local Variables:
  org-confirm-babel-evaluate: nil
  End:
